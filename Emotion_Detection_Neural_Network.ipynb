{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Emotion Detection Neural Network\n",
        "\n",
        "In this notebook I'll be:\n",
        "\n",
        "  1. Buildng Neural Networks to Predict Emotions\n",
        "  2. Implementing CNNs for Emotion Detection\n",
        "  3. Implementing Transfer Learning"
      ],
      "metadata": {
        "id": "JlZ5P6oHhB5v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwvGvKxaEybA"
      },
      "source": [
        "Prepare Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ0jXablFH76"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import pickle\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import itertools \n",
        "\n",
        "import urllib.request\n",
        "\n",
        "from sklearn import metrics\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm,tqdm_pandas\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "# grab tools from our tensorflow and keras toolboxes!\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import optimizers\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "def model_to_string(model):\n",
        "    import re\n",
        "    stringlist = []\n",
        "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "    sms = \"\\n\".join(stringlist)\n",
        "    sms = re.sub('_\\d\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d','', sms)  \n",
        "    return sms\n",
        "\n",
        "###Getting the csv data loaded\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/fer2013_5.csv\"\n",
        "\n",
        "###Getting the Dlib Shape predictor!\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/shape_predictor_68_face_landmarks.dat\"\n",
        "\n",
        "###Getting the Xpure loaded\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/pureX.npy\"\n",
        "\n",
        "###Getting the Xdata loaded\n",
        "!wget -q --show-progress -O ./dataX.npy \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/dataX_edited.npy\"\n",
        "\n",
        "###Getting the Ydata loaded\n",
        "!wget -q --show-progress \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Emotion%20Detection/dataY.npy\"\n",
        "\n",
        "print (\"Data Downloaded!\")\n",
        "\n",
        "'''\n",
        "Plots the confusion Matrix and saves it\n",
        "'''\n",
        "def plot_confusion_matrix(y_true,y_predicted):\n",
        "  cm = metrics.confusion_matrix(y_true, y_predicted)\n",
        "  print (\"Plotting the Confusion Matrix\")\n",
        "  labels = list(label_map.values())\n",
        "  df_cm = pd.DataFrame(cm,index = labels,columns = labels)\n",
        "  fig = plt.figure()\n",
        "  res = sns.heatmap(df_cm, annot=True,cmap='Blues', fmt='g')\n",
        "  plt.yticks([0.5,1.5,2.5,3.5,4.5], labels,va='center')\n",
        "  plt.title('Confusion Matrix - TestData')\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        " \n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def plot_graphs(history, best):\n",
        "  \n",
        "  plt.figure(figsize=[10,4])\n",
        "  # summarize history for accuracy\n",
        "  plt.subplot(121)\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy across training\\n best accuracy of %.02f'%best[1])\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.subplot(122)\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss across training\\n best loss of %.02f'%best[0])\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "#Integer to Label Mapping\n",
        "label_map = {\"0\":\"ANGRY\",\"1\":\"HAPPY\",\"2\":\"SAD\",\"3\":\"SURPRISE\",\"4\":\"NEUTRAL\"}\n",
        "\n",
        "\n",
        "#Load the 68 face Landmark file\n",
        "predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')\n",
        "\"\"\"\n",
        "Returns facial landmarks for the given input image path\n",
        "\"\"\"\n",
        "def get_landmarks(image):\n",
        "  \n",
        "  \n",
        "  #:type image : cv2 object\n",
        "  #:rtype landmarks : list of tuples where each tuple represents \n",
        "  #                  the x and y co-ordinates of facial keypoints\n",
        "  \n",
        "  #Bounding Box co-ordinates around the face(Training data is 48*48(cropped faces))\n",
        "  rects = [dlib.rectangle(left=1, top=1, right=47, bottom=47)]\n",
        "\n",
        "  #Read Image using OpenCV\n",
        "  #image = cv2.imread(image_path)\n",
        "  #Detect the Faces within the image\n",
        "  landmarks = [(p.x, p.y) for p in predictor(image, rects[0]).parts()]\n",
        "  return image,landmarks\n",
        "\n",
        "\"\"\"\n",
        "Display image with its Facial Landmarks\n",
        "\"\"\"\n",
        "def image_landmarks(image,face_landmarks):\n",
        "  \"\"\"\n",
        "  :type image_path : str\n",
        "  :type face_landmarks : list of tuples where each tuple represents \n",
        "                     the x and y co-ordinates of facial keypoints\n",
        "  :rtype : None\n",
        "  \"\"\"\n",
        "  radius = -4\n",
        "  circle_thickness = 1\n",
        "  image_copy = image.copy()\n",
        "  for (x, y) in face_landmarks:\n",
        "    cv2.circle(image_copy, (x, y), circle_thickness, (255,0,0), radius)\n",
        "    \n",
        "  plt.imshow(image_copy, interpolation='nearest')\n",
        "  plt.show()\n",
        "  \n",
        "\"\"\"\n",
        "Computes euclidean distance between 68 Landmark Points for our features\n",
        "e_dist is a list of features that will go into our model.\n",
        "Each feature is a distance between two landmark points, and every pair of points\n",
        "must have a feature.\n",
        "\"\"\"\n",
        "def landmarks_edist(face_landmarks):\n",
        "    e_dist = []\n",
        "    for i,j  in itertools.combinations(range(68), 2):\n",
        "      e_dist.append(distance.euclidean(face_landmarks[i],face_landmarks[j]))\n",
        "    return e_dist\n",
        "  \n",
        "def compare_learning(mlp, lm, cnn, vgg): # there's one model missing: MLP from pixels\n",
        "  \n",
        "  # summarize history for accuracy\n",
        "  plt.plot(vgg.history['val_accuracy'],)\n",
        "  plt.plot(cnn.history['val_accuracy'])\n",
        "  plt.plot(mlp.history['val_accuracy'],)\n",
        "  plt.plot(lm.history['val_accuracy'])\n",
        "  plt.ylabel('validitation accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['cnn_transfer', 'cnn_scratch', 'mlp_pixels', 'mlp_landmarks'], bbox_to_anchor=[1,1])\n",
        "  plt.xticks(range(0, epochs+1, 5), range(0, epochs+1, 5))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjE8097GFhRm"
      },
      "source": [
        "Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38duWv1GFicy"
      },
      "outputs": [],
      "source": [
        "perceptron = Sequential()\n",
        "perceptron.add(Dense(units = 1024, input_shape = (2278,),kernel_initializer='glorot_normal',activation = 'relu'))\n",
        "perceptron.add(Dense(units = 512,kernel_initializer='glorot_normal' , activation = 'relu'))\n",
        "perceptron.add(Dense(units = 5, activation = 'softmax'))\n",
        "perceptron.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHVlT7iWFky4"
      },
      "source": [
        "Testing if model is right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTiHGFbfFmWL"
      },
      "outputs": [],
      "source": [
        "perceptron_answer = Sequential()\n",
        "perceptron_answer.add(Dense(units = 1024, input_shape = (2278,),kernel_initializer='glorot_normal',activation = 'relu'))\n",
        "perceptron_answer.add(Dense(units = 512,kernel_initializer='glorot_normal' , activation = 'relu'))\n",
        "perceptron_answer.add(Dense(units = 5, activation = 'softmax'))\n",
        "    \n",
        "perceptron_answer.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=SGD(lr=0.001),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "if model_to_string(perceptron) == model_to_string(perceptron_answer):\n",
        "  print('Specification is correct!')\n",
        "else: \n",
        "  print('Error')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uqziXpXFwQC"
      },
      "source": [
        "Setting hyperparameters for all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tufy_eydFytN"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "batch_size = 64\n",
        "test_ratio = .1\n",
        "n_labels = 5 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfEWYLgCF6dU"
      },
      "source": [
        "Load unprocessed data from `Visualizing and Preparing Data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQbhJGI2GFjq"
      },
      "outputs": [],
      "source": [
        "dataX_pixels = np.load('pureX.npy')\n",
        "dataY_labels = np.load('dataY.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ehnrzc0GJ89"
      },
      "source": [
        "Convert labels to one-hot encoded labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sji-XzWkGOwO"
      },
      "outputs": [],
      "source": [
        "y_onehot = to_categorical(dataY_labels, len(set(dataY_labels)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_vwmTi_GR9t"
      },
      "source": [
        "Split standardized data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ulsr1xMbGT8q"
      },
      "outputs": [],
      "source": [
        "# split Data into Train, Test (90-10)\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataX_pixels, y_onehot, test_size=test_ratio, random_state=42)\n",
        "\n",
        "#### Standardize the data ##########\n",
        "pixel_scaler = StandardScaler()\n",
        "pixel_scaler.fit(X_train)\n",
        "X_train = pixel_scaler.transform(X_train)\n",
        "X_test = pixel_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8G-EkoaGXxj"
      },
      "source": [
        "Building a simple MLP for emotion detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM2I4ESFGfbd"
      },
      "outputs": [],
      "source": [
        "mlp_model = Sequential()\n",
        "mlp_model.add(Dense(5120, activation='relu',kernel_initializer='glorot_normal', input_shape=( X_train.shape[1]   ,)))\n",
        "mlp_model.add(Dropout(0.5))\n",
        "mlp_model.add(Dense(512,kernel_initializer='glorot_normal', activation='relu'))\n",
        "mlp_model.add(Dropout(0.5))\n",
        "mlp_model.add(Dense(256,kernel_initializer='glorot_normal', activation='relu'))\n",
        "mlp_model.add(Dropout(0.5))\n",
        "mlp_model.add(Dense(n_labels, activation='softmax'))\n",
        "\n",
        "mlp_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvUrKd1-GmJp"
      },
      "outputs": [],
      "source": [
        "# Compiling the model with SGD optimizer and categorical crossentropy loss\n",
        "mlp_model.compile(loss=categorical_crossentropy, optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
        "              \n",
        "#Saves the Best Model Based on Val Loss\n",
        "checkpoint = ModelCheckpoint('best_mlp_model.h5', verbose=1, monitor='val_accuracy', save_best_only=True,  mode='auto')  \n",
        "\n",
        "#training the model\n",
        "mlp_history = mlp_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n",
        "                            callbacks=[checkpoint], validation_data=(X_test, y_test), shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcsUBGuDGsYf"
      },
      "source": [
        "Evaluate the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjaz0ERsGt2Q"
      },
      "outputs": [],
      "source": [
        "mlp_performance = mlp_model.evaluate(X_test, y_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMVBTaR_Gw2B"
      },
      "source": [
        "Visualizing accuracy and loss over training + display best model's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lF2pT2mGzMB"
      },
      "outputs": [],
      "source": [
        "plot_graphs(mlp_history, mlp_performance); "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eyAE7VaG2v8"
      },
      "source": [
        "Plot the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dojK3THzG3pc"
      },
      "outputs": [],
      "source": [
        "y_pred_mlp = mlp_model.predict(X_test)\n",
        "y_pred_mlp_classes = np.argmax(y_pred_mlp, axis=1)\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "plot_confusion_matrix(y_true, y_pred_mlp_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1KMM77OG9fl"
      },
      "source": [
        "Evaluating the model on distance inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkWFG029HAit"
      },
      "outputs": [],
      "source": [
        "#Load the data (Distances between facial Landmarks)\n",
        "dataX_lm = np.load('./dataX.npy')\n",
        "\n",
        "# split Data into Train, Test (90-10)\n",
        "X_train_lm, X_test_lm, y_train_lm, y_test_lm = train_test_split(dataX_lm, y_onehot, test_size=0.1, random_state=42)\n",
        "\n",
        "#### Standardize the data #####\n",
        "lm_scaler = StandardScaler()\n",
        "lm_scaler.fit(X_train_lm)\n",
        "X_train_lm = lm_scaler.transform(X_train_lm)\n",
        "X_test_lm = lm_scaler.transform(X_test_lm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ToCjFkEHEBy"
      },
      "source": [
        "Building Model\n",
        "(Found out that building a model on the distances between facial landmarks did better than on raw pixel inputs in `Visualizing and Preparing Data`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBwm8AkAHFFX"
      },
      "outputs": [],
      "source": [
        "lm_model = Sequential()\n",
        "lm_model.add(Dense(5120, activation='relu',kernel_initializer='glorot_normal', input_shape=( X_train_lm.shape[1]   ,)))\n",
        "lm_model.add(Dropout(0.2))\n",
        "lm_model.add(Dense(512,kernel_initializer='glorot_normal', activation='relu'))\n",
        "lm_model.add(Dropout(0.2))\n",
        "lm_model.add(Dense(256,kernel_initializer='glorot_normal', activation='relu'))\n",
        "lm_model.add(Dropout(0.2))\n",
        "lm_model.add(Dense(n_labels, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFRB480OHMWr"
      },
      "outputs": [],
      "source": [
        "# Compiling the model with SGD optimizer and categorical crossentropy loss\n",
        "lm_model.compile(loss=categorical_crossentropy, optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
        "\n",
        "#Saves the Best Model Based on Val Loss\n",
        "checkpoint = ModelCheckpoint('best_lm_model.h5', verbose=1, monitor='val_loss',save_best_only=True,  mode='auto')  \n",
        "#training the model\n",
        "lm_history = lm_model.fit(X_train_lm, y_train_lm, batch_size=batch_size, epochs=epochs, \n",
        "                          verbose=1, callbacks=[checkpoint], validation_data=(X_test_lm, y_test_lm), shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOth1DtCHmEx"
      },
      "source": [
        "Evaluating this model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W03HuagNHonw"
      },
      "outputs": [],
      "source": [
        "lm_performance = lm_model.evaluate(X_test_lm, y_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYGrC305HuP9"
      },
      "source": [
        "Visualizing accuracy and loss over training + display best model's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT5Ntrn9HrO_"
      },
      "outputs": [],
      "source": [
        "plot_graphs(lm_history, lm_performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAM81O_4Hzsv"
      },
      "source": [
        "# Building Convulational Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXBUQ7iNIBSa"
      },
      "source": [
        "Model the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gjq4r5LH2dU"
      },
      "outputs": [],
      "source": [
        "width, height = 48, 48"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM3fPLvnID5e"
      },
      "source": [
        "Reshape the inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiuTAM1PIHI4"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRjr2yRHIJjs"
      },
      "outputs": [],
      "source": [
        "X_train_cnn = X_train.reshape(len(X_train),height,width)\n",
        "X_test_cnn = X_test.reshape(len(X_test),height,width)\n",
        "\n",
        "# converted them to images\n",
        "print(X_train_cnn.shape) \n",
        "#add one more dimension for model compatibility\n",
        "print(X_test_cnn.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsy6TMOPIQSz"
      },
      "outputs": [],
      "source": [
        "# now add one more dimension for model compatibility\n",
        "X_train_cnn = np.expand_dims(X_train_cnn,3)\n",
        "X_test_cnn = np.expand_dims(X_test_cnn,3)\n",
        "\n",
        "print(X_train_cnn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeJ8i3rWIVZE"
      },
      "source": [
        "BUILDING OUR MODEL !!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuaK5aZFIXyb"
      },
      "outputs": [],
      "source": [
        "cnn_model = Sequential()\n",
        "\n",
        "cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), kernel_regularizer=l2(0.01)))\n",
        "cnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "cnn_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "cnn_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "cnn_model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "cnn_model.add(Dense(512, activation='relu'))\n",
        "cnn_model.add(Dropout(0.4))\n",
        "cnn_model.add(Dense(256, activation='relu'))\n",
        "cnn_model.add(Dropout(0.4))\n",
        "cnn_model.add(Dense(128, activation='relu'))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(n_labels, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LfwVuK9EIvsr"
      },
      "outputs": [],
      "source": [
        "#Saves the Best Model Based on Val Loss\n",
        "checkpoint = ModelCheckpoint('best_cnn_model.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
        "\n",
        "# compliling the model with adam optimizer and categorical crossentropy loss\n",
        "cnn_model.compile(loss=categorical_crossentropy, optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999), metrics=['accuracy'])\n",
        "\n",
        "# training the model\n",
        "cnn_history = cnn_model.fit(X_train_cnn, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n",
        "                            callbacks=[checkpoint], validation_data=(X_test_cnn, y_test), shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcGVmfS7IxSo"
      },
      "source": [
        "Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5opQuPmxIzIr"
      },
      "outputs": [],
      "source": [
        "cnn_performance = cnn_model.evaluate(X_test_cnn, y_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laWea4uHI2fW"
      },
      "source": [
        "Plot accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDnXcXlhI4rI"
      },
      "outputs": [],
      "source": [
        "plot_graphs(cnn_history, cnn_performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1CpDeJKJJY5"
      },
      "source": [
        "Building a transfer learning model to check if it's more accurate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epZ0_5iDJLR3"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape, Dense, Conv2D, GlobalAveragePooling2D\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "# load the vgg network that is an 'expert' at 'imagenet' but do not include the FC layers\n",
        "vgg_expert = VGG16(weights = 'imagenet', include_top = False, input_shape = (48, 48, 3))\n",
        "\n",
        "# add the first 12 layers of vgg to our model vgg_model\n",
        "vgg_model = Sequential()\n",
        "vgg_model.add(vgg_expert)\n",
        "\n",
        "# add our layers on top of it\n",
        "vgg_model.add(GlobalAveragePooling2D())\n",
        "vgg_model.add(Dense(1024, activation = 'relu'))\n",
        "vgg_model.add(Dropout(0.3))\n",
        "vgg_model.add(Dense(512, activation = 'relu'))\n",
        "vgg_model.add(Dropout(0.3))\n",
        "vgg_model.add(Dense(5, activation = 'sigmoid'))\n",
        "\n",
        "# build the vgg model and turn it on \n",
        "vgg_model.compile(loss = 'categorical_crossentropy', \n",
        "          optimizer = SGD(lr=1e-4, momentum=0.95), \n",
        "          metrics=['accuracy'])\n",
        "\n",
        "X_TRAIN = np.array([np.transpose(np.array([X_train_cnn[ix].squeeze() for i in range(3)]), (1,2,0)) for ix in range(len(X_train))])\n",
        "X_TEST = np.array([np.transpose(np.array([X_test_cnn[ix].squeeze() for i in range(3)]), (1,2,0)) for ix in range(len(X_test))])\n",
        "\n",
        "#training the model\n",
        "vgg_history = vgg_model.fit(X_TRAIN, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          callbacks=[checkpoint],\n",
        "          validation_data=(X_TEST, y_test),\n",
        "          shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IiGXLlIJdrI"
      },
      "source": [
        "Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDQim4HnJonP"
      },
      "outputs": [],
      "source": [
        "vgg_performance = vgg_model.evaluate(X_TEST, y_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RryPLCQnJrDb"
      },
      "source": [
        "Visualize accuracy and loss over training + display best model's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6C17FS3Jtgr"
      },
      "outputs": [],
      "source": [
        "plot_graphs(vgg_history, vgg_performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi9eCD9fJ6YW"
      },
      "outputs": [],
      "source": [
        "compare_learning(mlp_history, lm_history, cnn_history, vgg_history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}